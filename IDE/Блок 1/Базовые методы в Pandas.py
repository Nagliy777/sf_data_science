
SERIES КАК СТРУКТУРА ДАННЫХ

#* Series — это упорядоченная изменяемая коллекция объектов, имеющая так называемые
#* ассоциативные метки (индексы).

#* Рассмотрим несколько способов создания Series на примере со списком названий стран.

Способ 1 — из списка с использованием параметров функции pd.Series():

countries = pd.Series(
    data = ['Англия', 'Канада', 'США', 'Россия', 'Украина', 'Беларусь', 'Казахстан'],
    index = ['UK', 'CA', 'US', 'RU', 'UA', 'BY', 'KZ'],
    name = 'countries'
)
display(countries)

Способ 2 — из словаря, в котором ключами являются будущие метки, а значениями
— будущие значения Series, при этом использование параметра name также возможно:
    
countries = pd.Series({
    'UK': 'Англия',
    'CA': 'Канада',
    'US' : 'США',
    'RU': 'Россия',
    'UA': 'Украина',
    'BY': 'Беларусь',
    'KZ': 'Казахстан'},
    name = 'countries'
)
display(countries)

#* Доступ к элементам осуществляется с использованием loc или iloc.

.loc вызывается с квадратными скобками, в которые передаются метки. 
print(countries.loc['US'])
# США

Для получения элемента по индексу "KZ" нужно обратиться через .iloc по номеру 6:

print(countries.iloc[6])
# Казахстан



#* DataFrame является двумерной структурой и представляется в виде таблицы,
#* в которой есть строки и столбцы: столбцами в DataFrame выступают объекты Series, 
#* а строки формируются из их элементов.
#* Также в DataFrame есть метки (индексы), которые соответствуют каждой строке таблицы.

#* Самый простой способ создания DataFrame — из словаря, ключами
#* которого являются имена столбцов будущей таблицы, а значениями — списки,
#* в которых хранится содержимое этих столбцов:
    
countries_df = pd.DataFrame({
    'country': ['Англия', 'Канада', 'США', 'Россия', 'Украина', 'Беларусь', 'Казахстан'],
    'population': [56.29, 38.05, 322.28, 146.24, 45.5, 9.5, 17.04],
    'square': [133396, 9984670, 9826630, 17125191, 603628, 207600, 2724902]
})


#* Также DataFrame можно создать из вложенного списка, внутренние списки
#* которого будут являться строками новой таблицы:

countries_df = pd.DataFrame(
    data = [
        ['Англия', 56.29, 133396],
        ['Канада', 38.05, 9984670],
        ['США', 322.28, 9826630],
        ['Россия', 146.24, 17125191],
        ['Украина', 45.5, 603628],
        ['Беларусь', 9.5, 207600],
        ['Казахстан', 17.04, 2724902]
    ],
    columns= ['country', 'population', 'square'],
    index = ['UK', 'CA', 'US', 'RU', 'UA', 'BY', 'KZ']
)
display(countries_df)   
    
#* В данном варианте создания DataFrame мы задаём имена столбцов в списке с
#* помощью параметра columns, а также инициализируем параметр index для задания меток стран.    
    
#! ДОСТУП К ДАННЫМ В DATAFRAME

Можно обратиться к DataFrame по имени столбца через точку:

countries_df.population

Другой вариант — обратиться к DataFrame по индексу и указать имя столбца:

countries_df['population']

Считаем среднее по строкам (axis = 0) в каждом столбце:
countries_df.mean(axis=0, numeric_only=True)

Считаем среднее по столбцам (axis = 1) в каждой строке:
countries_df.mean(axis=1, numeric_only=True)

#! ЗАПИСЬ В CSV-ФАЙЛ

Экспорт данных в формат csv осуществляется с помощью метода DataFrame to_csv().

Основные параметры метода DataFrame to_csv()

path_or_buf — путь до файла, в который будет записан DataFrame (например, data/my_data.csv);
sep — разделитель данных в выходном файле (по умолчанию ',');
decimal — разделитель чисел на целую и дробную части в выходном файле (по умолчанию '.');
columns — список столбцов, которые нужно записать в файл (по умолчанию записываются все столбцы);
index — параметр, определяющий, требуется ли создавать дополнительный столбец с индексами строк в файле (по умолчанию True).

Пример:
countries_df = pd.DataFrame({
    'country': ['Англия', 'Канада', 'США', 'Россия', 'Украина', 'Беларусь', 'Казахстан'],
    'population': [56.29, 38.05, 322.28, 146.24, 45.5, 9.5, 17.04],
    'square': [133396, 9984670, 9826630, 17125191, 603628, 207600, 2724902]
})

countries_df.to_csv('data/countries.csv', index=False, sep=';')

#! ЧТЕНИЕ CSV-ФАЙЛА
Для чтения таблицы из csv-файла используется функция модуля Pandas read_csv.
Функция возвращает DataFrame и имеет несколько важных параметров.

filepath_or_buffer — путь до файла, который мы читаем;
sep — разделитель данных (по умолчанию ',');
decimal — разделитель чисел на целую и дробную часть в выходном файле (по умолчанию '.');
names — список с названиями столбцов для чтения;
skiprows — количество строк в файле, которые нужно пропустить (например, файл может содержать служебную информацию, которая нам не нужна).

countries_data = pd.read_csv('data/countries.csv', sep=';')
display(countries_data)

#! ЧТЕНИЕ CSV-ФАЙЛА ПО ССЫЛКЕ

На самом деле файл с данными не обязательно должен храниться у вас на компьютере. 
Если он находится в открытом доступе по ссылке (например, на Google Диске или GitHub), 
его можно прочитать и из интернета — для этого достаточно в функции read_csv() вместо пути до файла указать ссылку на файл. Например:
data = pd.read_csv('https://raw.githubusercontent.com/esabunor/MLWorkspace/master/melb_data.csv')
display(data)

#! ЗАПИСЬ И ЧТЕНИЕ В ДРУГИХ ФОРМАТАХ

Методы для записи таблиц в файлы отличных от csv форматов:

to_excel() — запись DataFrame в формат Excel-таблицы (.xlsx);
to_json() — запись DataFrame в формат JSON (.json);
to_xml() — запись DataFrame в формат XML-документа (.xml);
to_sql() — запись DataFrame в базу данных SQL (для реализации этого метода необходимо установить соединение с базой данных).

Методы для чтения таблиц из файлов в отличных от csv форматах:

read_excel() — чтение из формата Excel-таблицы (.xlsx) в DataFrame;
read_json() — чтение из формата JSON (.json) в DataFrame;
read_xml() — чтение из формата XML-документа (.xml) в DataFrame;
read_sql() — чтение из базы данных SQL в DataFrame (также необходимо установить соединение с базой данных).

#! ВЫВОД ПЕРВЫХ И ПОСЛЕДНИХ СТРОК

Для этого у DataFrame есть методы head() и tail(), которые возвращают
n первых и n последних строк таблицы соответственно (по умолчанию n = 5).
Следующий код выведет семь последних строк нашей таблицы:
melb_data.tail(7)

#! РАЗМЕРНОСТЬ ТАБЛИЦЫ
Далее хотелось бы узнать размер таблицы — количество строк и количество столбцов.
Это можно сделать с помощью атрибута shape, который возвращает кортеж с количеством строк и столбцов:
 melb_data.shape
# (13580, 23)

#! ПОЛУЧЕНИЕ ИНФОРМАЦИИ О СТОЛБЦАХ
# Для того чтобы получить более детальную информацию о столбцах таблицы,
# можно использовать метод DataFrame info():
# melb_data.info()

Данный метод выводит:

# информацию об индексах;
# информацию об общем количестве столбцов;
# таблицу, в которой содержится информация об именах столбцов (Column), количестве непустых значений (Non-Null Count) в каждом столбце и типе данных столбца (Dtype), количестве столбцов, в которых используется определённый тип данных;
# количество оперативной памяти в мегабайтах, которое тратится на хранение данных.

#! ИЗМЕНЕНИЕ ТИПА ДАННЫХ В СТОЛБЦЕ
Можно воспользоваться методом astype(), который позволяет преобразовать тип данных столбца:
melb_data['Car'] = melb_data['Car'].astype('int64')
melb_data['Bedroom'] = melb_data['Bedroom'].astype('int64')

#! ПОЛУЧЕНИЕ ОПИСАТЕЛЬНОЙ СТАТИСТИКИ
Часто при работе с таблицей нужно быстро посмотреть на основные статистические
свойства её столбцов. Для этого можно воспользоваться методом DataFrame describe().

Чтобы не увязнуть в обилии информации, выведем на экран значение статистических
параметров только для столбцов Distance (расстояние от объекта недвижимости до центра Мельбурна),
BuildingArea (площадь здания) и Price (цена объекта):

melb_data.describe().loc[:, ['Distance', 'BuildingArea' , 'Price']]

 На самом деле метод describe() можно применять не только к числовым признакам.
 С помощью параметра include можно указать тип данных, для которого нужно вывести описательную информацию.
 
Например, для типа данных object метод describe() возвращает DataFrame, в котором указаны:

количество непустых строк (count);
количество уникальных значений (unique);
самое частое значение — мода —  (top);
частота — объём использования — этого значения (freq) для каждого столбца типа object исходной таблицы.
melb_data.describe(include=['object'])

#! ПОЛУЧЕНИЕ ЧАСТОТЫ УНИКАЛЬНЫХ ЗНАЧЕНИЙ В СТОЛБЦЕ
Для того чтобы определить, сколько раз в столбце повторяется каждый из вариантов значений 
(т.е. найти частоту для каждого уникального знания), используется метод value_counts().

Чтобы сделать вывод более интерпретируемым и понятным, можно воспользоваться параметром normalize.
При установке значения этого параметра на True результат будет представляться в виде доли
(относительной частоты):
melb_data['Regionname'].value_counts(normalize=True)

#! АГРЕГИРУЮЩИЕ МЕТОДЫ
Агрегирующим в Pandas называется метод, который для каждого столбца возвращает только одно значение
— показатель (например, вычисление медианы, максимума, среднего и так далее).

#! МЕТОД	СТАТИСТИЧЕСКИЙ ПАРАМЕТР
.count()	Количество непустых значений
.mean()	Среднее значение
.min()	Минимальное значение
.max()	Максимальное значение
.var()	Дисперсия
.std()	Стандартное отклонение
.sum()	Сумма
.quantile(x)	Квантиль уровня x
.nunique()	Число уникальных значений

Если один из этих методов применить ко всему DataFrame, то в результате его работы будет получен
объект типа Series, в котором в качестве индексов будут выступать наименования столбцов,
а в качестве значений — статистический показатель. В случае применения метода к отдельному столбцу результатом вычислений станет число.
print(melb_data['Price'].mean())

#! МОДАЛЬНОЕ ЗНАЧЕНИЕ
Модальных значений может быть несколько, то есть несколько значений могут встречаться
одинаковое количество раз. Поэтому метод mode(), в отличие от агрегирующих методов, возвращает не одно число, а серию.
print(melb_data['Rooms'].mode())
# 0    3
# dtype: int64

#! Фильтрация данных в DataFrame
#* Маской называется Series, которая состоит из булевых значений, при этом значения True
#* соответствуют тем индексам, для которых заданное условие выполняется, в противном случае
#* ставится значение False (например, цена > 2 млн).

mask = melb_data['Price'] > 2000000
display(melb_data[mask].head())
melb_data[melb_data['Price'] > 2000000]

#* Найдём количество зданий с тремя комнатами. Для этого отфильтруем таблицу по условию:
#* обратимся к результирующей таблице по столбцу Rooms и найдём число строк в ней
#* с помощью атрибута shape:
melb_data[melb_data['Rooms'] == 3].shape[0]

#* Условия можно комбинировать, используя операторы & (логическое И)
#* и | (логическое ИЛИ). Условия при этом заключаются в скобки.
#* Усложним прошлый пример и найдём число трёхкомнатных домов с ценой менее 300 тысяч:
melb_data[(melb_data['Rooms'] == 3) & (melb_data['Price'] < 300000)].shape[0]    

#* Таких зданий оказалось всего три. Немного «ослабим» условие: теперь нас будут интересовать
#* дома с ценой менее 300 тысяч, у которых либо число комнат равно 3 либо
#* площадь домов более 100 квадратных метров:
melb_data[((melb_data['Rooms'] == 3) | (melb_data['BuildingArea'] > 100)) & (melb_data['Price'] < 300000)].shape[0]

#* Примечание. Обратите внимание, что использование привычных операторов and и or будет
#* неверным и приведёт к ошибке, так как они выполняют логические операции между двумя булевыми
#* числами. В нашем случае слева и справа от оператора стоят маски (объекты Series),
#* для которых логическую операцию надо совершить поэлементно, а операторы and и or для такого не предназначены.

#* Давайте найдём максимальное количество комнат в таунхаусах. Так как в результате
#* фильтрации получается DataFrame, то обратимся к нему по столбцу Rooms и найдём максимальное значение:
melb_data[melb_data['Type'] == 't']['Rooms'].max()

#* А теперь более сложный трюк: найдём медианную площадь здания у объектов,
#* чья цена выше средней. Для того чтобы оградить наш код от нагромождений,
#* предварительно создадим переменную со средней ценой:
mean_price = melb_data['Price'].mean()
melb_data[melb_data['Price'] > mean_price]['BuildingArea'].median()

#*Фильтрация по трём числам
melb_data[melb_data['BuildingArea'].isin([15,20,25])] 

#*Фильтрация без пустых значений
melb_data[melb_data['BuildingArea'].notna()] 

#*Фильтрация пустых значений
melb_data[melb_data['BuildingArea'].isna()] 

#*Количество пустых значений
melb_data['BuildingArea'].isna().sum()

#todo Базовые приёмы Pandas

#! СОЗДАНИЕ КОПИИ ТАБЛИЦЫ
Создадим копию melb_df с помощью метода copy():
melb_df = melb_data.copy()
melb_df.head()

#! УДАЛЕНИЕ СТОЛБЦОВ
Это может быть полезно, например, когда в данных есть признаки, которые не несут полезной информации.

За удаление строк и столбцов в таблице отвечает метод drop().
labels — порядковые номера или имена столбцов, которые подлежат удалению; если их несколько,
то передаётся список;

axis — ось совершения операции, axis=0 — удаляются строки, axis=1 — удаляются столбцы;

inplace — если параметр выставлен на True, происходит замена изначального DataFrame на новый,
при этом метод ничего не возвращает; если на False — возвращается копия DataFrame, из которой
удалены указанные строки (столбцы), при этом первоначальный DataFrame не изменяется; по умолчанию
параметр равен False.

Удалим столбцы index и Coordinates из таблицы с помощью метода drop(). 
Выведем первые пять строк таблицы и убедимся, что всё прошло успешно.
melb_df = melb_df.drop(['index', 'Coordinates'], axis=1)

Альтернативный вариант:
melb_df.drop(['index','Coordinates'],axis=1,inplace=True)

#! МАТЕМАТИЧЕСКИЕ ОПЕРАЦИИ СО СТОЛБЦАМИ

Все операции со столбцами совершаются поэлементно, очень быстро, а самое главное — без написания циклов.
total_rooms = melb_df['Rooms'] + melb_df['Bedroom'] + melb_df['Bathroom']
display(total_rooms)

А теперь введём признак MeanRoomsSquare, который соответствует средней площади одной комнаты
для каждого объекта. Для этого разделим площадь здания на полученное ранее общее количество комнат:
melb_df['MeanRoomsSquare'] = melb_df['BuildingArea'] / total_rooms
display(melb_df['MeanRoomsSquare'])

Можно ввести ещё один интересный признак — AreaRatio, коэффициент соотношения площади здания
(BuildingArea) и площади участка (Landsize). Для этого разницу двух площадей поделим на их сумму:
diff_area = melb_df['BuildingArea'] - melb_df['Landsize']
sum_area = melb_df['BuildingArea'] + melb_df['Landsize']
melb_df['AreaRatio'] = diff_area/sum_area    
    
#! ФОРМАТ DATETIME

Таким форматом в Pandas является формат datetime, который записывается как 
YYYY-MM-DD HH: MM: SS, то есть составляющие времени указываются в следующем порядке:
год, месяц, день, час, минута, секунда.

Для того чтобы преобразовывать столбцы с датами, записанными в распространённых форматах,
в формат datetime, можно воспользоваться функцией pandas.to_datetime(). В нашем случае
в функции нужно указать параметр dayfirst=True, который будет обозначать, что в первоначальном
признаке первым идет день. Преобразуем столбец Date в формат datetime, передав его в эту функцию:
melb_df['Date'] = pd.to_datetime(melb_df['Date'], dayfirst=True)

В результате мы переопределяем признак Date в формат datetime
Стоит обратить внимание, что изменился тип данных для столбца Date, теперь его тип — datetime64.
Рассмотрим несколько возможностей этого типа данных.

#! ВЫДЕЛЕНИЕ АТРИБУТОВ DATETIME

date — дата;
year, month, day — год, месяц, день;
time — время;
hour, minute, second — час, минута, секунда;
dayofweek — номер дня недели, от 0 до 6, где 0 — понедельник, 6 — воскресенье;
day_name — название дня недели;
dayofyear — порядковый день года;
quarter — квартал (интервал в три месяца).

Например, обратившись по атрибуту dt.year в столбце Date, мы можем «достать»
год продажи и понять, за какой интервал времени (в годах) представлены наши данные,
а также на какой год приходится наибольшее число продаж:
    
years_sold = melb_df['Date'].dt.year
print(years_sold)
print('Min year sold:', years_sold.min())
print('Max year sold:', years_sold.max())
print('Mode year sold:', years_sold.mode()[0])

В результате обращения к атрибуту datetime melb_df['Date'].dt.year мы получаем объект Series,
в котором в качестве значений выступают годы продажи объектов недвижимости. 

Теперь попробуем понять, на какие месяцы приходится пик продаж объектов недвижимости. Для этого
выделим атрибут dt.month и на этот раз занесём результат в столбец MonthSale, а затем
найдём относительную частоту продаж для каждого месяца от общего количества продаж — для этого
используем метод value_counts() с параметром normalize (вывод в долях):
melb_df['MonthSale'] = melb_df['Date'].dt.month
melb_df['MonthSale'].value_counts(normalize=True)

#! РАБОТА С ИНТЕРВАЛАМИ

Например, можно вычислить, сколько дней прошло с 1 января 2016 года до момента продажи объекта.
Для этого можно просто найти разницу между датами продаж и заявленной датой, представленной в формате datetime:
delta_days = melb_df['Date'] - pd.to_datetime('2016-01-01') 

В результате мы получаем Series, элементами которой является количество дней, 
которое прошло с 1 января 2016 года. Обратите внимание, что данные такого формата относятся к типу timedelta.
Чтобы превратить количество дней из формата интервала в формат целого числа дней,
можно воспользоваться аксессором dt для формата timedelta и извлечь из него атрибут days:
    
display(delta_days.dt.days)


Пример:
#* Напишите функцию get_weekend(weekday), которая принимает на вход элемент столбца WeekdaySale
#* и возвращает 1, если день является выходным, и 0 — в противном случае, и создайте столбец Weekend
#* в таблице melb_df с помощью неё.

def get_weekend(weekday):
    if weekday == 5 or weekday == 6:
        return 1
    else:
        return 0
    
    
#* Преобразуйте столбец SellerG с наименованиями риелторских компаний в таблице melb_df следующим образом:
#* оставьте в столбце только 49 самых популярных компаний, а остальные обозначьте как 'other'.
#* Найдите, во сколько раз минимальная цена объектов недвижимости, проданных компанией 'Nelson',
#* больше минимальной цены объектов, проданных компаниями, обозначенными как 'other'. Ответ
#* округлите до десятых.

popular_SellerG=melb_df['SellerG'].value_counts().nlargest(49).index
melb_df['SellerG'] = melb_df['SellerG'].apply(lambda x: x if x in popular_SellerG else 'other')
display(melb_df[melb_df['SellerG']=='Nelson']['Price'].min()/melb_df[melb_df['SellerG']=='other']['Price'].min())

#! ПРИЗНАКИ: КАТЕГОРИАЛЬНЫЕ И ЧИСЛОВЫЕ

#todo Рассмотрим такие статистические термины, как категориальные и числовые признаки.

#* Под числовыми признаками обычно подразумевают признаки, которые отражают количественную меру
#* и могут принимать значения из неограниченного диапазона.

#todo Числовые признаки могут быть:

дискретными (например, количество комнат, пациентов, дней);
непрерывными (например, масса, цена, площадь).
#* Дискретные признаки чаще всего представлены целыми числами, а непрерывные
#* — целыми числами и числами с плавающей точкой.

#todo Под категориальными признаками обычно подразумевают столбцы в таблице, которые
#todo обозначают принадлежность объекта к какому-то классу/категории.

#*Категориальные признаки могут быть:

номинальными (например, пол, национальность, район);
порядковыми (например, уровень образования, уровень комфорта, стадия заболевания).
#* Такие признаки имеют ограниченный набор значений. Они чаще всего представлены в виде
#* текстового описания и кодируются в Pandas типом данных object.

#! КАТЕГОРИИ В ДАННЫХ О НЕДВИЖИМОСТИ

#* Давайте определим число уникальных категорий в каждом столбце нашей таблицы melb_df. 
#* Для этого создадим вспомогательную таблицу unique_counts:

# создаём пустой список
unique_list = []
# пробегаемся по именам столбцов в таблице
for col in melb_df.columns:
    # создаём кортеж (имя столбца, число уникальных значений)
    item = (col, melb_df[col].nunique(),melb_df[col].dtypes)     # добавляем кортеж в список
    unique_list.append(item) 
# создаём вспомогательную таблицу и сортируем её
unique_counts = pd.DataFrame(
    unique_list,
    columns=['Column_Name', 'Num_Unique', 'Type']
).sort_values(by='Num_Unique',  ignore_index=True)
# выводим её на экран
display(unique_counts)

#! ТИП ДАННЫХ CATEGORY
#* Для хранения и оптимизации работы с категориальными признаками в Pandas предусмотрен
#* специальный тип данных — category.

#* этот тип данных расширяет возможности работы с категориальными признаками: мы можем легко
#* преобразовывать категории, строить графики по таким данным (что сложно сделать для типа данных object).
#* Также резко повышается производительность операций, совершаемых с такими столбцами.

#todo Самый простой способ преобразования столбцов к типу данных category — это использование уже
#todo знакомого нам метода astype(), в параметры которого достаточно передать строку 'category'.

#* Сделаем преобразование столбцов к типу данных category:
    
cols_to_exclude = ['Date', 'Rooms', 'Bedroom', 'Bathroom', 'Car'] # список столбцов, которые мы не берём во внимание
max_unique_count = 150 # задаём максимальное число уникальных категорий
for col in melb_df.columns: # цикл по именам столбцов
    if melb_df[col].nunique() < max_unique_count and col not in cols_to_exclude: # проверяем условие
        melb_df[col] = melb_df[col].astype('category') # преобразуем тип столбца
display(melb_df.info())

#! ПОЛУЧЕНИЕ АТРИБУТОВ CATEGORY

#* У типа данных category есть свой специальный аксесcор cat, который позволяет получать
#* информацию о своих значениях и преобразовывать их. Например, с помощью атрибута этого аксессора
#* categories мы можем получить список уникальных категорий в столбце Regionname:
print(melb_df['Regionname'].cat.categories)

#* А теперь посмотрим, каким образом столбец кодируется в виде чисел в памяти компьютера.
#* Для этого можно воспользоваться атрибутом codes:
display(melb_df['Regionname'].cat.codes)

#* С помощью метода аксессора rename_categories() можно легко переименовать текущие
#* значения категорий. Для этого в данный метод нужно передать словарь, ключи которого — 
#* старые имена категорий, а значения — новые.
#todo Рассмотрим на примере: переименуем категории признака типа постройки Type — заменим
#todo их на полные названия (напомним, u — unit, h — house, t — townhouse).
melb_df['Type'] = melb_df['Type'].cat.rename_categories({
    'u': 'unit',
    't': 'townhouse',
    'h': 'house'
})
display(melb_df['Type'])

#* тип данных category хранит только категории, которые были объявлены при его инициализации.
#* При встрече с новой, неизвестной ранее категорией, этот тип превратит её в пустое значение,
#* так как он просто не знает о существовании этой категории.

#todo Решить эту проблему на самом деле не сложно. Можно добавить категорию flat в столбец Type
#todo с помощью метода акссесора cat add_categories(), в который достаточно просто передать имя
#todo новой категории:
melb_df['Type'] = melb_df['Type'].cat.add_categories('flat')
new_houses_types = pd.Series(['unit', 'house', 'flat', 'flat', 'house'])
new_houses_types = new_houses_types.astype(melb_df['Type'].dtype)
display(new_houses_types)

#* Примечание. Добавление новой категории в столбец Type не отразится на самом столбце —
#* текущие категории не изменятся, однако такое преобразование позволит добавлять в таблицу
#* новые данные о домах с новой категорией — flat.