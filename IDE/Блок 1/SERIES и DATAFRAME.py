
SERIES КАК СТРУКТУРА ДАННЫХ

#* Series — это упорядоченная изменяемая коллекция объектов, имеющая так называемые
#* ассоциативные метки (индексы).

#* Рассмотрим несколько способов создания Series на примере со списком названий стран.

Способ 1 — из списка с использованием параметров функции pd.Series():

countries = pd.Series(
    data = ['Англия', 'Канада', 'США', 'Россия', 'Украина', 'Беларусь', 'Казахстан'],
    index = ['UK', 'CA', 'US', 'RU', 'UA', 'BY', 'KZ'],
    name = 'countries'
)
display(countries)

Способ 2 — из словаря, в котором ключами являются будущие метки, а значениями
— будущие значения Series, при этом использование параметра name также возможно:
    
countries = pd.Series({
    'UK': 'Англия',
    'CA': 'Канада',
    'US' : 'США',
    'RU': 'Россия',
    'UA': 'Украина',
    'BY': 'Беларусь',
    'KZ': 'Казахстан'},
    name = 'countries'
)
display(countries)

#* Доступ к элементам осуществляется с использованием loc или iloc.

.loc вызывается с квадратными скобками, в которые передаются метки. 
print(countries.loc['US'])
# США

Для получения элемента по индексу "KZ" нужно обратиться через .iloc по номеру 6:

print(countries.iloc[6])
# Казахстан



#* DataFrame является двумерной структурой и представляется в виде таблицы,
#* в которой есть строки и столбцы: столбцами в DataFrame выступают объекты Series, 
#* а строки формируются из их элементов.
#* Также в DataFrame есть метки (индексы), которые соответствуют каждой строке таблицы.

#* Самый простой способ создания DataFrame — из словаря, ключами
#* которого являются имена столбцов будущей таблицы, а значениями — списки,
#* в которых хранится содержимое этих столбцов:
    
countries_df = pd.DataFrame({
    'country': ['Англия', 'Канада', 'США', 'Россия', 'Украина', 'Беларусь', 'Казахстан'],
    'population': [56.29, 38.05, 322.28, 146.24, 45.5, 9.5, 17.04],
    'square': [133396, 9984670, 9826630, 17125191, 603628, 207600, 2724902]
})


#* Также DataFrame можно создать из вложенного списка, внутренние списки
#* которого будут являться строками новой таблицы:

countries_df = pd.DataFrame(
    data = [
        ['Англия', 56.29, 133396],
        ['Канада', 38.05, 9984670],
        ['США', 322.28, 9826630],
        ['Россия', 146.24, 17125191],
        ['Украина', 45.5, 603628],
        ['Беларусь', 9.5, 207600],
        ['Казахстан', 17.04, 2724902]
    ],
    columns= ['country', 'population', 'square'],
    index = ['UK', 'CA', 'US', 'RU', 'UA', 'BY', 'KZ']
)
display(countries_df)   
    
#* В данном варианте создания DataFrame мы задаём имена столбцов в списке с
#* помощью параметра columns, а также инициализируем параметр index для задания меток стран.    
    
#! ДОСТУП К ДАННЫМ В DATAFRAME

Можно обратиться к DataFrame по имени столбца через точку:

countries_df.population

Другой вариант — обратиться к DataFrame по индексу и указать имя столбца:

countries_df['population']

Считаем среднее по строкам (axis = 0) в каждом столбце:
countries_df.mean(axis=0, numeric_only=True)

Считаем среднее по столбцам (axis = 1) в каждой строке:
countries_df.mean(axis=1, numeric_only=True)

#! ЗАПИСЬ В CSV-ФАЙЛ

Экспорт данных в формат csv осуществляется с помощью метода DataFrame to_csv().

Основные параметры метода DataFrame to_csv()

path_or_buf — путь до файла, в который будет записан DataFrame (например, data/my_data.csv);
sep — разделитель данных в выходном файле (по умолчанию ',');
decimal — разделитель чисел на целую и дробную части в выходном файле (по умолчанию '.');
columns — список столбцов, которые нужно записать в файл (по умолчанию записываются все столбцы);
index — параметр, определяющий, требуется ли создавать дополнительный столбец с индексами строк в файле (по умолчанию True).

Пример:
countries_df = pd.DataFrame({
    'country': ['Англия', 'Канада', 'США', 'Россия', 'Украина', 'Беларусь', 'Казахстан'],
    'population': [56.29, 38.05, 322.28, 146.24, 45.5, 9.5, 17.04],
    'square': [133396, 9984670, 9826630, 17125191, 603628, 207600, 2724902]
})

countries_df.to_csv('data/countries.csv', index=False, sep=';')

#! ЧТЕНИЕ CSV-ФАЙЛА
Для чтения таблицы из csv-файла используется функция модуля Pandas read_csv.
Функция возвращает DataFrame и имеет несколько важных параметров.

filepath_or_buffer — путь до файла, который мы читаем;
sep — разделитель данных (по умолчанию ',');
decimal — разделитель чисел на целую и дробную часть в выходном файле (по умолчанию '.');
names — список с названиями столбцов для чтения;
skiprows — количество строк в файле, которые нужно пропустить (например, файл может содержать служебную информацию, которая нам не нужна).

countries_data = pd.read_csv('data/countries.csv', sep=';')
display(countries_data)

#! ЧТЕНИЕ CSV-ФАЙЛА ПО ССЫЛКЕ

На самом деле файл с данными не обязательно должен храниться у вас на компьютере. 
Если он находится в открытом доступе по ссылке (например, на Google Диске или GitHub), 
его можно прочитать и из интернета — для этого достаточно в функции read_csv() вместо пути до файла указать ссылку на файл. Например:
data = pd.read_csv('https://raw.githubusercontent.com/esabunor/MLWorkspace/master/melb_data.csv')
display(data)

#! ЗАПИСЬ И ЧТЕНИЕ В ДРУГИХ ФОРМАТАХ

Методы для записи таблиц в файлы отличных от csv форматов:

to_excel() — запись DataFrame в формат Excel-таблицы (.xlsx);
to_json() — запись DataFrame в формат JSON (.json);
to_xml() — запись DataFrame в формат XML-документа (.xml);
to_sql() — запись DataFrame в базу данных SQL (для реализации этого метода необходимо установить соединение с базой данных).

Методы для чтения таблиц из файлов в отличных от csv форматах:

read_excel() — чтение из формата Excel-таблицы (.xlsx) в DataFrame;
read_json() — чтение из формата JSON (.json) в DataFrame;
read_xml() — чтение из формата XML-документа (.xml) в DataFrame;
read_sql() — чтение из базы данных SQL в DataFrame (также необходимо установить соединение с базой данных).

#! ВЫВОД ПЕРВЫХ И ПОСЛЕДНИХ СТРОК

Для этого у DataFrame есть методы head() и tail(), которые возвращают
n первых и n последних строк таблицы соответственно (по умолчанию n = 5).
Следующий код выведет семь последних строк нашей таблицы:
melb_data.tail(7)

#! РАЗМЕРНОСТЬ ТАБЛИЦЫ
Далее хотелось бы узнать размер таблицы — количество строк и количество столбцов.
Это можно сделать с помощью атрибута shape, который возвращает кортеж с количеством строк и столбцов:
 melb_data.shape
# (13580, 23)

#! ПОЛУЧЕНИЕ ИНФОРМАЦИИ О СТОЛБЦАХ
# Для того чтобы получить более детальную информацию о столбцах таблицы,
# можно использовать метод DataFrame info():
# melb_data.info()

Данный метод выводит:

# информацию об индексах;
# информацию об общем количестве столбцов;
# таблицу, в которой содержится информация об именах столбцов (Column), количестве непустых значений (Non-Null Count) в каждом столбце и типе данных столбца (Dtype), количестве столбцов, в которых используется определённый тип данных;
# количество оперативной памяти в мегабайтах, которое тратится на хранение данных.

#! ИЗМЕНЕНИЕ ТИПА ДАННЫХ В СТОЛБЦЕ
Можно воспользоваться методом astype(), который позволяет преобразовать тип данных столбца:
melb_data['Car'] = melb_data['Car'].astype('int64')
melb_data['Bedroom'] = melb_data['Bedroom'].astype('int64')

#! ПОЛУЧЕНИЕ ОПИСАТЕЛЬНОЙ СТАТИСТИКИ
Часто при работе с таблицей нужно быстро посмотреть на основные статистические
свойства её столбцов. Для этого можно воспользоваться методом DataFrame describe().

Чтобы не увязнуть в обилии информации, выведем на экран значение статистических
параметров только для столбцов Distance (расстояние от объекта недвижимости до центра Мельбурна),
BuildingArea (площадь здания) и Price (цена объекта):

melb_data.describe().loc[:, ['Distance', 'BuildingArea' , 'Price']]

 На самом деле метод describe() можно применять не только к числовым признакам.
 С помощью параметра include можно указать тип данных, для которого нужно вывести описательную информацию.
 
Например, для типа данных object метод describe() возвращает DataFrame, в котором указаны:

количество непустых строк (count);
количество уникальных значений (unique);
самое частое значение — мода —  (top);
частота — объём использования — этого значения (freq) для каждого столбца типа object исходной таблицы.
melb_data.describe(include=['object'])

#! ПОЛУЧЕНИЕ ЧАСТОТЫ УНИКАЛЬНЫХ ЗНАЧЕНИЙ В СТОЛБЦЕ
Для того чтобы определить, сколько раз в столбце повторяется каждый из вариантов значений 
(т.е. найти частоту для каждого уникального знания), используется метод value_counts().

Чтобы сделать вывод более интерпретируемым и понятным, можно воспользоваться параметром normalize.
При установке значения этого параметра на True результат будет представляться в виде доли
(относительной частоты):
melb_data['Regionname'].value_counts(normalize=True)

#! АГРЕГИРУЮЩИЕ МЕТОДЫ
Агрегирующим в Pandas называется метод, который для каждого столбца возвращает только одно значение
— показатель (например, вычисление медианы, максимума, среднего и так далее).

#! МЕТОД	СТАТИСТИЧЕСКИЙ ПАРАМЕТР
.count()	Количество непустых значений
.mean()	Среднее значение
.min()	Минимальное значение
.max()	Максимальное значение
.var()	Дисперсия
.std()	Стандартное отклонение
.sum()	Сумма
.quantile(x)	Квантиль уровня x
.nunique()	Число уникальных значений

Если один из этих методов применить ко всему DataFrame, то в результате его работы будет получен
объект типа Series, в котором в качестве индексов будут выступать наименования столбцов,
а в качестве значений — статистический показатель. В случае применения метода к отдельному столбцу результатом вычислений станет число.
print(melb_data['Price'].mean())

#! МОДАЛЬНОЕ ЗНАЧЕНИЕ
Модальных значений может быть несколько, то есть несколько значений могут встречаться
одинаковое количество раз. Поэтому метод mode(), в отличие от агрегирующих методов, возвращает не одно число, а серию.
print(melb_data['Rooms'].mode())
# 0    3
# dtype: int64

#! Фильтрация данных в DataFrame
#* Маской называется Series, которая состоит из булевых значений, при этом значения True
#* соответствуют тем индексам, для которых заданное условие выполняется, в противном случае
#* ставится значение False (например, цена > 2 млн).

mask = melb_data['Price'] > 2000000
display(melb_data[mask].head())
melb_data[melb_data['Price'] > 2000000]

#* Найдём количество зданий с тремя комнатами. Для этого отфильтруем таблицу по условию:
#* обратимся к результирующей таблице по столбцу Rooms и найдём число строк в ней
#* с помощью атрибута shape:
melb_data[melb_data['Rooms'] == 3].shape[0]

#* Условия можно комбинировать, используя операторы & (логическое И)
#* и | (логическое ИЛИ). Условия при этом заключаются в скобки.
#* Усложним прошлый пример и найдём число трёхкомнатных домов с ценой менее 300 тысяч:
melb_data[(melb_data['Rooms'] == 3) & (melb_data['Price'] < 300000)].shape[0]    

Таких зданий оказалось всего три. Немного «ослабим» условие: теперь нас будут интересовать
дома с ценой менее 300 тысяч, у которых либо число комнат равно 3 либо
площадь домов более 100 квадратных метров:
melb_data[((melb_data['Rooms'] == 3) | (melb_data['BuildingArea'] > 100)) & (melb_data['Price'] < 300000)].shape[0]

Примечание. Обратите внимание, что использование привычных операторов and и or будет
неверным и приведёт к ошибке, так как они выполняют логические операции между двумя булевыми
числами. В нашем случае слева и справа от оператора стоят маски (объекты Series),
для которых логическую операцию надо совершить поэлементно, а операторы and и or для такого не предназначены.

Давайте найдём максимальное количество комнат в таунхаусах. Так как в результате
фильтрации получается DataFrame, то обратимся к нему по столбцу Rooms и найдём максимальное значение:
melb_data[melb_data['Type'] == 't']['Rooms'].max()

А теперь более сложный трюк: найдём медианную площадь здания у объектов,
чья цена выше средней. Для того чтобы оградить наш код от нагромождений,
предварительно создадим переменную со средней ценой:
mean_price = melb_data['Price'].mean()
melb_data[melb_data['Price'] > mean_price]['BuildingArea'].median()

