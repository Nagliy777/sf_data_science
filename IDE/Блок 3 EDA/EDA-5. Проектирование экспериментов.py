
#! Введение в проектирование экспериментов

#* Машинное обучение (ML) — это область компьютерных наук, которая использует алгоритмы для создания
#* и обучения моделей для выполнения рутинных задач. 

#* Точность модели (accuracy) машинного обучения определяется как процент правильных прогнозов для
#* тестовых данных и рассчитывается путём деления количества правильных прогнозов на общее количество
#* прогнозов. Обычно это определяющий фактор при оценке успеха проекта машинного обучения — чем выше
#* точность, тем лучше работает модель машинного обучения. 

#* Например, вы оцениваете спрос на товар. Ваша цель — узнать, купит ли клиент продукт. Вы строите модель
#* на основе данных и реальных ответов, а затем сравниваете свои предсказания и реальные ответы. Если
#* предсказания совпадают с реальными ответами чаще, чем в 90 % случаях, то обычно говорят, что модель надёжна,
#* и её можно использовать для предсказаний спроса уже других клиентов. 

КАК ДОБИТЬСЯ ЛУЧШЕЙ ТОЧНОСТИ МОДЕЛИ ML?

#* Чтобы оптимизировать метрики для тестовых данных, необходимо пространство для многочисленных
#* экспериментов. Экспериментирование с различными архитектурами моделей, кодом предварительной
#* обработки и параметрами модели, определяющими успех процесса обучения, несколько раз приводит
#* к повторному обучению модели. Всё это вы будете изучать в будущих модулях, посвящённых моделированию в ML.  

#* Возникает необходимость отслеживания экспериментов, то есть сохранения всей важной информации,
#* связанной с каждым запускаемым экспериментом, например сохранение параметров запуска, влияющих
#* на производительность модели. Выполнять эту задачу вручную обременительно, поэтому имеет смысл
#* поставить для процесса автоматизированную инфраструктуру — пайплайн (pipeline) машинного обучения.

#* Пайплайном (pipeline) в ML называется способ систематизации и автоматизации рабочего процесса,
#* необходимого для создания модели машинного обучения. Пайплайны состоят из нескольких последовательных
#* шагов, которые выполняют всё — от извлечения и предварительной обработки данных до обучения и
#* проверки моделей.

#* Этот рабочий процесс позволяет осуществлять непрерывную настройку существующих моделей наряду с
#* постоянной оценкой производительности. Самым большим преимуществом этого процесса является то,
#* что его можно автоматизировать с помощью доступных инструментов.

#* Для медицинских стартапов это означает, что они могут получить модель машинного обучения для
#* конкретного проекта, которая будет постоянно обновляться по мере поступления новых данных о
#* пациентах, что приведёт к более высокой точности полученных результатов.

#? Давайте на примере подробно разберём проектирование экспериментов и построение пайплайна. 

#todo Представьте, что вы специалист по данным, а ваша компания сотрудничает с медицинскими учреждениями.
#todo Перед вами стоит задача выяснить, почему люди, получившие инструкции по лечению, не приходят на
#todo следующий приём. В качестве набора данных вы используете информацию о посещениях и характеристики
#todo пациентов. 

#todo Каждая история болезни характеризуется следующими признаками:

#* No_show — пациент не пришёл на приём;
#* Gender — пол пациента;
#* ScheduledDay — день, когда планируется встреча;
#* AppointmentDay — реальная дата встречи;
#* Age — возраст пациента;
#* Neighbourhood — район проживания каждого пациента;
#* Scholarship — получает ли пациент стипендию;
#* …и несколько других признаков.

#todo 1 Первым этапом данных является загрузка данных: 
df = pd.read_csv('./KaggleV2-May-2016.csv')

#* Основная цель проекта — выделить факторы, способствующие пропуску встреч с врачом. Однако
#* это долгосрочная цель. Прежде чем копнуть глубже, необходимо попытаться ответить на следующие вопросы:

#* Каково соотношение людей, которые пропускают встречи, к тем, кто этого не делает?
#* Кто не появляется чаще — мужчины или женщины?
#todo 2 Для ответа на эти и другие подобные вопросы используется EDA.

#todo Найти соотношение людей, которые пропускают приёмы, к тем, кто этого не делает, можно с помощью гистограммы:
plt.figure(figsize=(8,4))
df['No-show'].hist()
plt.title('Соотношение людей, которые пропускают приемы, к тем, кто этого не делает');

#todo Или, если мы хотим получить точную пропорцию, — с помощью метода value_counts():

df['No-show'].value_counts(True)
привет как дела
#todo Данный метод также может помочь оценить, кто не появляется чаще — мужчины или женщины:

df[df['No-show']=='Yes']['Gender'].value_counts(True)

#* Итак, мы видим, что людей, пропускающих приём, примерно 20 %.

#todo 3. После того, как выполнен разведывательный анализ данных, переходим к предобработке данных.
#todo  Некоторые столбцы, например ‘Gender’ и ‘Neighbourhood’, представлены в текстовом виде, а модели
#todo  машинного обучения работают с числовыми признаками. Необходимо закодировать такие данные.
#todo  Для one-hot кодировки можно воспользоваться методом get_dummies() библиотеки pandas:

categorical_columns_names = ['Gender', 'Neighbourhood']
encoded_columns = pd.get_dummies(df, columns = categorical_columns_names)

#todo4. После этих этапов можно переходить к созданию предсказания, придёт ли пациент на приём, обучению и
#todo оптимизации модели, а также выделению наиболее важных признаков, способствующих высокой производительности
#todo модели. Об этом вы узнаете в будущих модулях!  

#* Предположим, вы несколько раз обучили модель с разными параметрами, подобрали наилучшие и достигли
#* [Math Processing Error]. То есть доля верных предсказаний превышает 90 %. Также вы узнали, что
#* наибольший вклад в модель вносят такие признаки, как пол, регион и факт наличия стипендии. Про
#* влияние пола на результат вы догадались во время проведения EDA, регион кажется тоже понятным
#* фактором: люди в крупных городах больше склонны приходить на последующий назначенный прием, а
#* вот факт наличия стипендии — не такой очевидный фактор. 

#* Это подтверждает тезис о том, что модели машинного обучения могут рассматриваться как чёрный ящик:
#* нечто, куда мы кладём свои данные и получаем предсказание. Не всегда результаты прогнозов легко
#* интерпретируемы. Обычно существует трэйд-офф между качеством модели и её интерпретируемостью:
#* чем сложнее модель, тем выше, но менее очевиден её результат.    

#? Логирование экспериментов

#* Итак, запуск экспериментов по машинному обучению включает в себя множество задач, таких как EDA
#* и предобработка данных. В последнюю может входить заполнение пропусков данных, проверка различных
#* алгоритмов с целью поиска наилучшего, анализ производительности модели и другие связанные задачи,
#* которые зависят от решаемой проблемы.

#* Как вы уже знаете, в процессе проведения эксперимента по машинному обучению можно использовать функцию
#* print() для просмотра выходных данных экспериментов, таких как уровень корреляции данных в выборке,
#* результат тестирования статистической гипотезы и так далее. 

#* Однако время от времени выводить результат на экран с помощью функции print() бесполезно, так как при
#* запуске следующего эксперимента вы потеряете все результаты предыдущего эксперимента, если не запишете
#* их вручную в документ. 

#* Таким образом, сравнение результатов ML-экспериментов становится весьма затруднительным процессом, потому
#* что необходимо иметь записи всех проводимых ранее экспериментов. Например, если во время EDA-задачи
#* предсказания спроса на лекарство изменяются данные, то каждый раз выводить на экран новую визуализацию
#* неудобно. 

#* Логирование решает эту проблему! Даже если информация изменится с запуском нового эксперимента, всё будет
#* зафиксировано в логе. 

#todo Лог (log) — это специальный журнал, в котором хранится информация о состоянии работы программы.
#todo Логирование (ведение журнала) обеспечивает отслеживание событий, происходящих во время работы
#todo программы, и может выводить эти события в отдельный файл, чтобы вы могли отслеживать,
#todo что происходит во время выполнения кода. 

#todo Для логирования в Python используется модуль logging.

import logging

#todo Прежде чем приступить к логированию, необходимо установить базовые настройки:

#* уровень;
#* обработчик (хендлер);
#* формат логирования. 

#* С импортированным модулем logging вы можете использовать так называемый «logger» для логирования
#* сообщений, которые вы хотите видеть (вместо вывода их на экран командой print()). 

#* По умолчанию существует пять стандартных уровней логирования, указывающих на важность событий: 

#* отладка;
#* информация;
#* предупреждение;
#* ошибка;
#* критический. 
#* Самый низкий уровень из данных — не установлен, а самый высокий уровень является критическим.
#* Установив уровень логирования, можно записать сообщение специально для этого уровня в определённый
#* файл журнала. Возле сообщения будет указан его уровень.

import logging
logging.debug('This is a debug message')
logging.info('This is an informational message')
logging.warning('This message is a warning')
logging.error('This is an error message')
logging.critical('This is a critical message')

#todo Здесь мы дали команду залогировать пять сообщений. Вывод команд показывает уровень важности перед
#todo каждым сообщением (WARNING/ERROR/CRITICAL). root — имя логгера по умолчанию.

#* Обратите внимание, что сообщения debug() и info() не были отображены. Это связано с тем, что по умолчанию
#* модуль ведения журнала регистрирует сообщения только с уровнем ПРЕДУПРЕЖДЕНИЕ (WARNING) или выше. Вы
#* можете изменить это, сконфигурировав модуль logging для регистрации событий всех уровней, то есть
#* установив уровень на ОТЛАДКУ (DEBUG). 

#* Чтобы сделать это, нужно сначала сбросить настройки библиотеки logging — воспользоваться функцией
#* reload() из вспомогательной системной библиотеки importlib:
from importlib import reload
import logging
reload(logging)

from importlib import reload
import logging
reload(logging)
#* Далее, когда настройки логирования сброшены, нам необходимо перед выводом сообщений, сразу после импорта,
#* изменить конфигурацию логгера.

logging.basicConfig(level=logging.DEBUG)

#* Мы настроили уровень ведения журнала DEBUG. Это означает, что теперь будут отслеживаться только сообщения
#* этого уровня (DEBUG) и выше. В результате выполнения кода логирования мы должны получить следующие
#* сообщения:

#* DEBUG:root:This is a debug message
#* INFO:root:This is an informational message
#* WARNING:root:This message is a warning
#* ERROR:root:This is an error message
#* CRITICAL:root:This is a critical message

#? УСТАНОВКА ОБРАБОТЧИКА ЛОГИРОВАНИЯ

#* Функция обработчиков ведения журналов состоит в том, чтобы отображать записи/сообщения журнала
#* на любом выходе, который вы выберете. То есть вы можете выбрать, отображать ли ваш лог в виде файла,
#* HTTP-страницы или даже отправить лог на электронную почту через SMTP. 

#* Более того, у созданного вами logger может быть несколько обработчиков, а это значит, что вы можете 
#* настроить его на сохранение в файл журнала, а также на отправку по email одновременно.

#todo Обработчики являются классами модуля logging. Нам понадобится обработчик FileHandler, который возьмёт
#todo запись/сообщение журнала и добавит его в файл журнала log_file.log:

logging.FileHandler('log_file.log')

#? УСТАНОВКА ФОРМАТА ЛОГИРОВАНИЯ
#* Как мы уже сказали, типичный формат лога выглядит так: уровень: имя: сообщение.
#* Однако его можно изменить.

#todo Существуют различные способы форматирования записи журнала. Вы можете включить дату, время
#todo и уровень ведения журнала в свой формат, чтобы знать, когда журнал был отправлен и на каком уровне.
#todo В приведённом ниже примере показано, как можно настроить формат записей журнала. Так как мы вновь
#todo переопределяем настройки библиотеки logging, то не забудем сбросить конфигурацию.

from importlib import reload
import logging
reload(logging)
 
logging.basicConfig(
    format="%(levelname)s: %(asctime)s: %(message)s",
    level=logging.DEBUG
)
logging.info('Check')

#* Здесь формат записей журнала включает дату, время, уровень ведения журнала и само сообщение.

#todo Таким образом, вы можете изменять как формат лога, так и формат вывода. Добавление времени сообщения
#todo существенно облегчает работу — становится легко отследить, когда было получено сообщение.

#? Знакомство с Comet.ml

#todo Comet.ml — это онлайн-платформа, позволяющая отслеживать эксперименты. Основное преимущество Comet
#todo состоит в том, что с её помощью можно легко построить панель отчётности и систему мониторинга.

#* Comet предоставляет следующие возможности:

#* сравнивать эксперименты с точки зрения метрик, параметров и так далее;
#* следить за моделью от создания до вывода в продакшен;
#* делиться своим проектом с другими людьми, которые в режиме реального времени будут следить за результатами;
#* строить отчёты исходя из результатов эксперимента;
#* оставить проект приватным или сделать его общедоступным.

#todo Платформа генерирует новый API для эксперимента, который можно использовать в коде Python:

from comet_ml import Experiment

# Создайте эксперимент с помощью вашего API ключа
experiment = Experiment(
    api_key="УКАЖИТЕ ЗДЕСЬ СВОЙ КЛЮЧ API",
    project_name="medical-appointment",
    workspace="УКАЖИТЕ ЗДЕСЬ ИМЯ СВОЕЙ УЧЕТНОЙ ЗАПИСИ",
)

#todo Класс Experiment — это интерфейс локального кода для Comet. Он определяет множество методов,
#todo описанных в официальной документации Comet. Платформа позволяет хранить информацию о коде,
#todo логировать графики, гиперпараметры модели (о них вы узнаете дальше в курсе), метрики. 

#* Давайте рассмотрим некоторые популярные методы:

#* log_metric() и log_metrics() — логируют в эксперименте одну или несколько оценочных метрик,
#* таких как accuracy;
#* log_figure() — логирует рисунок;
#* display() — создаёт интерактивную среду в Jupyter, показывающую приборную панель Comet как вывод ячейки;
#* end() — если эксперимент выполняется в Jupyter, этот метод указывает, что эксперимент завершён.

#* После завершения эксперимента Comet предоставляет информационную панель, где можно увидеть все
#* залогированные в коде метрики, цифры, параметры и так далее.

#* Показатели оценки отображаются автоматически. Например, если эксперимент состоит из нескольких шагов,
#* можно легко нарисовать графики, показывающие метрики в зависимости от количества шагов.

#todo Итак, Comet.ml — это платформа для экспериментов с машинным обучением, которую специалисты по данным
#todo используют для отслеживания, сравнения и объяснения своих экспериментов по машинному обучению. Она
#todo обеспечивает воспроизведение моделей, простое обслуживание рабочего процесса машинного обучения и
#todo бесперебойную совместную работу на протяжении всего жизненного цикла проекта.  

