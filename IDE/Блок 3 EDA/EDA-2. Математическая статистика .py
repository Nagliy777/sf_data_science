
#! Введение

#* Статистика очень тесно связана с машинным обучением. Этот раздел математики помогает ответить,
#* какие из признаков важны, позволяет выдвигать и проверять гипотезы и идеи. Статистика лежит в
#* основе алгоритмов машинного обучения, методов разведывательного анализа данных. С элементами
#* математической статистики мы столкнёмся в каждом модуле этого курса.

#todo Математическая статистика — раздел математики, который занимается систематизацией
#todo и обработкой данных для их использования и получения выводов.

#* Данные, собранные в ходе исследования каких-то явлений или процессов, сами по себе не очень
#* информативны. Чтобы извлечь из данных какие-то полезные идеи, применяется описательная статистика,

#todo Статистические данные — упорядоченные, классифицированные данные о каком-то явлении или процессе.

#? Описательная статистика. Меры центральной тенденции в Python

#* Когда вы описываете и вычисляете характеристики одной переменной, вы выполняете одномерный анализ. 
#* Когда вы анализируете пару переменных и больше, то вы делаете многомерный анализ. 
#* Целью такого анализа является нахождение связей между признаками. 


#todo Мера центральной тенденции — это число, которое описывает так называемое «среднее» признака.
#todo Мера центральной тенденции может рассчитываться по-разному в зависимости от типа признака
#todo или от его распределения.

#* Далее мы рассмотрим наиболее популярные меры центральной тенденции, используемые в машинном обучении:
#* среднее арифметическое, медиана, мода. Для расчёта этих описательных статистик в Python мы будем
#* пользоваться библиотекой statistics. Она предоставляет готовые функции для вычисления математической
#* статистики для числовых данных.

#* Установим библиотеку:
pip install statistics
#* Импортируем библиотеку для дальнейшего использования:
import statistics

#* Среднее арифметическое — сумма всех элементов, поделённая на количество элементов в числовом
#* ряду или признаке (Series).

#* Вычислите среднюю стоимость бутылки вина при помощи функции statistics.mean() библиотеки statistics.
#* Округлите значение до сотых.
round(statistics.mean(data['price']),2)

#? МЕДИАНА

#todo Медиана — средний элемент распределения. Для расчёта медианы должно выполняться одно условие:
#todo числовой ряд должен быть предварительно отсортирован. Только так мы сможем корректно рассчитать
#todo средний элемент. Признак может быть отсортирован как по возрастанию, так и по убыванию. 

#* Методы современных библиотек, в том числе и используемой нами statistics для вычисления медианы,
#* самостоятельно выполняют сортировку данных — вам не нужно заботиться об этом. 
#* Если количество элементов чётное, медианой будет среднее арифметическое двух средних элементов распределения.

statistics.median(data['price']) 


#* В отличие от среднего арифметического медиана хорошо справляется с разбросом в значениях,
#* поэтому её чаще используют.

#* Также медиана разбивает данные на две группы, состоящие из одинакового количества элементов.
#* Средние значения, например уровень дохода или цена на недвижимость, часто вычисляются именно
#* по медиане, потому что в этом случае важен средний уровень доходов большей части населения. 

#* В таком случае основатель Amazon Джефф Безосс с годовым доходом в несколько миллиардов не
#* испортит нам всю статистику. 

#todo Также в библиотеке statistics есть функции, связанные с медианой, — функция
#todo  statistics.median_low() и функция statistics.median_high().
#* В случае, когда количество элементов чётное, у нас получается два средних значения:
median_low() возвращает меньшее из них;
median_high() возвращает большее из них.

#todo Примечание. Если в вашем наборе данных есть пропущенные значения, функции библиотеки statistics
#todo в отличие от других методов (например np.median() из библиотеки numpy) будут автоматически игнорировать
#todo пропущенные значения, не выдавая ошибку.

#? МОДА

#todo Мода — самое часто встречающееся значение в числовом или нечисловом ряду данных.

#* Чаще всего мода используется в нечисловых рядах. Например самая популярная порода собак,
#* фильм года, лучшие рестораны вычисляются именно модой.

statistics.mode(data['price'])

#todo Моду также можно вычислить при помощи statistics.multimode(). В случае наличия нескольких модовых
#todo (популярных значений) функция statistics.mode() вернёт вам ошибку StatisticsError,
#todo а statistics.multimode() — список с всеми вычисленными модовыми значениями.

#* Мы рассмотрели самые основные и часто используемые в машинном обучении меры центральной тенденции.
#*  Также к мерам центральной тенденции относятся:

#* среднее геометрическое;
#* среднее гармоническое;
#* средневзвешенное и другие.

#! Корреляция

#todo Корреляция — статистическая связь двух и более переменных. При изменении значения одной из
#todo переменных происходит закономерное изменение другой или других величин. 

#* Мерой связи величин, мерой корреляции является коэффициент корреляции. Он может принимать
#* значение от -1 до +1.

#todo Отрицательная корреляция, коэффициент корреляции < 0 говорит об обратной связи между переменными.
#* При обратной связи увеличение одной из величин ведёт к закономерному уменьшению другой (других) величин.
#* Например, чем больше сумма активного долга, тем меньше шанс в одобрении кредита. 

#todo Положительная корреляция, коэффициент корреляции > 0 говорит о прямой связи между переменными.
#* При прямой связи увеличение одной из величин ведёт к закономерному увеличению другой (других) величин. 
#* Например, с увеличением возраста размер ноги человека увеличивается, и его рост увеличивается тоже.

#* Коэффициент корреляции = 0 говорит о том, что переменные независимы друг от друга, по крайней мере
#* линейно, но это вовсе не значит, что между ними нет какой-то более сложной взаимосвязи. Это
#* достаточно редкое явление, которое может встретиться на конкретном наборе данных.

#* Понимание корреляции приводит нас к понятию мультиколлинеарности — такой сильной зависимости
#* переменных друг от друга, что она затрудняет анализ и оценку будущей модели машинного обучения.

#todo      В таблице отражены основные силы связи между признаками.

#* Сила связи	                           Значение коэффициента корреляции
#* Отсутствие связи или очень слабая связь	      0…+/- 0.3
#* Слабая связь	                              +/- 0.3…+/- 0.5
#* Средняя связь	                           +/- 0.5…+/- 0.7
#* Сильная связь	                          +/- 0.7…+/- 0.9
#* Очень сильная или абсолютная связь	         +/- 0.9…+/-1 

#todo Принято считать, что при коэффициенте корреляции +/-0,7 связь между признаками
#todo сильная и приводит к мультиколлинеарности.

#* Например, сложилась ситуация, когда в датасете были обнаружены признаки с очень сильной корреляцией.
#* Мы знаем, что мультиколлинеарность вредит такой модели, поэтому на этапе проектирования признаков
#* можем объединить эту пару признаков в один или удалить из этой пары один — тот, что менее важен.
#* Важность признаков мы оцениваем позже, на этапе отбора признаков.

#todo Для расчёта коэффициента корреляции применим функцию df.corr() библиотеки pandas.
data[['price','points']].corr()

#* Результатом функции df.corr() является матрица корреляции. 

#todo Матрица корреляции — таблица, заголовками и строками которой являются названия признаков в датасете.
#todo На пересечении строк и столбцов находится значение коэффициента корреляции этих двух признаков.

#* Корреляция и причинно-следственная связь — это понятия, которые чаще всего ошибочно приравниваются друг
#* к другу. Понимание корреляции важно для разведывательного анализа и помогает делать правильные выводы. 

#? ЛОЖНАЯ КОРРЕЛЯЦИЯ

#* Рассмотрим, почему корреляция не подразумевает причинно-следственных связей, на популярном примере.
#* Продажи мороженого коррелируют с убийствами!
#* По мере роста или падения продаж замороженного десерта соответственно растёт или уменьшается количество убийств. Является ли потребление замороженного десерта причиной смерти людей?
#* Нет. Эти две вещи взаимосвязаны, но это не значит, что одна вызывает другую.

#todo  Нет причинно-следственной связи между убийствами и продажей мороженого, а наличие третьего
#todo  фактора — хорошей погоды — объясняет эти связи. Этот случай называется ложной корреляцией.

#! Типы корреляций. Корреляция Пирсона

#* Метод df.corr() принимает в себя несколько аргументов.
#* method - Название метода расчёта коэффициента корреляции.
#* Аргумент method указывает на название используемого метода расчёта корреляции:
#* 'pearson' — корреляция Пирсона, 'kendall' — корреляция Кендалла,
#* 'spearman' — корреляция Спирмена. Каждый метод может быть применён
#* для разных типов данных. Давайте разберёмся, чем отличаются эти методы
#* и для каких типов данных применять каждый из них.

#? КОРРЕЛЯЦИЯ ПИРСОНА

#* Рассчитав в прошлом юните коэффициент корреляции между point и price, мы использовали df.corr().
#* Согласно документации, если не указать method, по умолчанию используется корреляция Пирсона.
#* Верно ли это для наших признаков?

#* Коэффициент корреляции Пирсона используется для вычисления линейной взаимосвязи между признаками. 

#todo Линейная взаимосвязь — вид связи между признаками, в котором изменение одного признака
#todo x1 всегда приводит к изменению другого признака x2 на величину, пропорциональную изменению x1,
#todo в соответствии с правилом:x2=ax1+b  (уравнение прямой), где a и b — некоторые коэффициенты.

#* Определить существование линейной связи в паре признаков эмпирическим путем можно,
#* если вы можете формулировать фразу про признаки: «С уменьшением/увеличением признака
#* 1 уменьшается/увеличивается признак 2 в соответствии с некоторым уравнением прямой». 
#* Например, с увеличением возраста заёмщика уменьшается количество дней просрочки по кредиту. 

#? НОРМАЛЬНОЕ РАСПРЕДЕЛЕНИЕ

#* Большинство окружающих нас процессов и явлений, характеристик объектов можно описать нормальным
#* распределением. В основном это переменные, которые зависят от множества факторов, например рост
#* человека. Он сформировался благодаря местности, в которой проживает человек, генетическим
#* предрасположенностям, перенесённым заболеваниям и так далее. Как следствие, показатели роста
#* подвергаются законам нормального распределения.

#* Если признак является совокупностью очень редких событий, например аварии на дорогах, то
#* распределение признака нормальным не будет.

#* Cхематичное изображение нормального распределения, график q-q plot.

#* На гистограмме распределение должно напоминать колокол (левый график на рисунке),
#* а q-q plot должен напоминать прямую линию (правый график на рисунке).

#todo Код для построения графиков:

import matplotlib.pyplot as plt # библиотека визуализации
from scipy import stats # библиотека для расчетов

plt.subplot(1, 2, 1) # задаем сетку рисунка количество строк и столбцов
stats.probplot(df['price'], plot=plt) # qq plot

plt.subplot(1, 2, 2) # располагаем второй рисунок рядом
plt.hist(df['price']) # гистограмма распределения признака

plt.tight_layout() # чтобы графики не наезжали другу на друга, используем tight_layout

plt.show() # просмотр графика

#todo Кажется, признак распределён ненормально, так как q-q plot имеет изогнутую линию,
#todo а гистограмма распределения совершенно не похожа на колокол.

#* Такой признак при анализе Пирсоном может выдать некорректные результаты. Для таких
#* случаев существуют другие виды корреляций или проводится операция по приведению
#* признака к нормальному путём преобразований, которые вы освоите позже, в юнитах
#* про разведывательный анализ данных.

#todo Корреляция между непрерывными признаками, которые имеют близкое к нормальному распределение,
#todo может быть рассчитана с использованием стандартной корреляции Пирсона. 

#todo Для категориальных данных используется методы ранговой корреляции, например Спирмена и Кендалла,
#todo которые будут изучены в следующем юните. 

#todo Для непрерывных переменных, имеющих большое количество выбросов или распределённых ненормально,
#todo могут использоваться методы по устранению выбросов и нормализации данных, которые будут изучены
#todo далее в курсе. Также могут быть использованы методы ранговой корреляции.

#todo В следующем юните вы познакомитесь c другими типами корреляции: Спирмена, Кендалла и Мэтьюса.

#! Типы корреляций. Ранговые корреляции

#todo Ранговая корреляция — это вид корреляции, отражающий отношения переменных, упорядоченных по 
#todo возрастанию их значения. Ранги — это порядковые номера единиц совокупности в упорядоченном
#todo (ранжированном) ряду. Если проранжировать совокупность по двум признакам, связь между
#todo которыми изучается, то полное совпадение рангов означает максимально тесную прямую связь,
#todo а полная противоположность рангов — максимально тесную обратную связь.

#? КОРРЕЛЯЦИЯ СПИРМЕНА
#todo Коэффициент корреляции Спирмена используется для вычисления взаимосвязей между
#todo категориальными переменными.

#* Чтобы рассчитать коэффициент корреляции Спирмена, вам необходимо передать в df.corr()
#* аргумент method = 'spearman' 
data[['price','points']].corr(method = 'spearman')

#todo  Иногда мы можем применить ранговую корреляцию и для числовых переменных,
#todo  которые распределены ненормально или если между ними существует нелинейная связь. 

#* В нашем случае один из признаков price распределён ненормально, связь между ними также не
#* является линейной. Корреляция по Пирсону составляет 0.4, что говорит о слабой связи признаков.
#* А корреляция по Спирмену составляет 0.58, что говорит о более сильной связи. 

#? КОРРЕЛЯЦИЯ КЕНДАЛЛА

#* Так же, как и корреляция Спирмена, корреляция Кендала предусмотрена для нахождения взаимосвязей
#* между категориальными переменными. Для расчёта коэффициента корреляции Кендалла необходимо передать
#* в изученный нами метод df.corr() аргумент method = 'kendall'. 
data[['price','points']].corr(method = 'kendall')

#todo Корреляции Спирмена и Кендалла очень похожи. Чтобы понять их различия, необходимо глубокое погружение
#todo в их математическую природу. Однако в среднем корреляция Кендала выдаёт меньшие значения коэффициента
#todo корреляции, чем корреляция Спирмена. 

#* Корреляция Кендалла более устойчива к ошибкам и выбросам в данных. Это значит, что её можно
#* применить до очистки данных, чтобы выявить взаимосвязи заранее. Применение в этом случае
#* корреляции Спирмена, как и корреляции Пирсона, не вызовет ошибки, но, скорее всего, некорректность
#* расчёта приведёт к неверным выводам.

#? КОРРЕЛЯЦИЯ МЭТЬЮСА

#todo Корреляция Мэтьюса — мера силы связи между бинарными переменными.

#* В df.corr() нет расчёта для корреляции Мэтьюса, но мы можем воспользоваться библиотекой scikit-learn
#* и её функцией matthews_corrcoef() для расчёта коэффициента корреляции Мэтьюса.

#* scikit-learn — это библиотека с реализацией готовых алгоритмов для машинного обучения.
#*  Более подробно вы познакомитесь с ней в модулях, посвящённых машинному обучению.

#* Для начала установим библиотеку scikit-learn.
#* pip install scikit-learn

#* Затем импортируем нужную нам функцию для дальнейшей работы.
from sklearn.metrics import matthews_corrcoef

x = [+1, -1, +1, +1] # список значений признака х
y = [+1, +1, +1, -1] # список значений признака y

matthews_corrcoef(x, y)

#* Коэффициент корреляции Мэтьюса может быть полезен в случае, когда в датасете представлены
#* только бинарные переменные. Кроме того, этот коэффициент используется для оценки качества моделей,
#* ответы которых также бинарны. 

#todo Например, при предсказании дефолтности клиента у нас может быть только два исхода:
#todo 1 — дефолт, 0 — не дефолт.

#! Визуализация корреляций. Матрица корреляций. График рассеивания. Парные отношения в наборе данных

#? МАТРИЦА КОРРЕЛЯЦИЙ

#* В случае большого количества данных в датасете матрица, возвращаемая методом pandas data.corr(),
#* становится нечитаемой.

#todo Постройте матрицу корреляций для датасета. В ответ впишите самый высокий коэффициент корреляции.
#todo Ответ округлите до сотых.
data.corr(numeric_only=True)

#* Матрица получилась большой и потребовалось достаточно много времени, чтобы проанализировать все
#* коэффициенты в этой матрице. А если признаков будет больше? Найти что-то в ней будет практически
#* невозможно. Поэтому специалисты по данным отдают предпочтение методам визуализации. Один из
#* таких — тепловая матрица корреляций.

#? ТЕПЛОВАЯ МАТРИЦА КОРРЕЛЯЦИЙ
 
#* Для построения такой матрицы нам будет необходима знакомая нам из модуля по визуализации
#* библиотека seaborn.

#*Импортируем библиотеку для дальнейшего использования:

import seaborn as sns
#* Для построения тепловой матрицы корреляций мы воспользуемся методом sns.heatmap() библиотеки seaborn. 

#* Метод принимает на вход двумерный массив данных под аргументом data. Это может быть матрица корреляций,
#* полученная методом df.corr(), матрица пропущенных значений, полученная методом df.isnull(),
#* набор данных и многое другое. 

#todo Передадим в метод heatmap() нашу матрицу корреляций corr():
sns.heatmap(data.corr(numeric_only=True))
#* Чтобы было удобнее её интерпретировать, передадим параметр annot = True,
#* чтобы отобразить коэффициент корреляции на пересечении признаков.
sns.heatmap(data.corr(numeric_only=True), annot = True)

#* в тёплых светлых оттенках отражена положительная корреляция между признаками, в тёмных
#* холодных — отрицательная корреляция.

#* С помощью такой матрицы очень удобно оценивать мультиколлинеарность в данных, делать выводы 
#* о связях между признаками.

#? SCATTERPLOT
#* Иногда нам необходимо рассмотреть связь между признаками как распределение.
#* Матрица корреляции может показать нам только силу связи и её направление (плюс/минус).
#* Чтобы рассмотреть распределение и характер связи, существует точечная диаграмма рассеивания.

#todo Точечная диаграмма рассеивания — это такая диаграмма, в которой каждое значение,
#todo которое принимает признак в датасете, отражено точкой.

#* Для построения точечной диаграммы рассеивания мы воспользуемся знакомой нам библиотекой seaborn,
#* которой мы пользовались при построении тепловой матрицы корреляции.

#* Метод, который мы будем использовать, — sns.scatterplot(). Он отражает связь между переменными,
#* где есть аргументы метода x, y, и признаки, которые мы хотим исследовать.

#todo Возьмём для примера две пары признаков:

#* по оси x="Waist/Hip" — соотношение обхвата талии/бедер, по оси y="Waist" — обхват талии;
sns.scatterplot(data=data, x="Waist/Hip", y="Waist")

#* по оси x="Weight" — вес модели, а по оси y="Year" — год размещения модели в журнале.
sns.scatterplot(data=data, x="Weight", y="Year")

#* Сравнив эти два графика, мы можем сказать, что в первой паре признаков связь видна более отчётливо,
#* точки больше прижаты друг к другу и выстроены визуально в линию. Эта линия похожа на рассматриваемую
#* нами в прошлом юните линейную связь. Во второй паре признаков они распределены по всему
#* пространству — трудно выявить основную массу признаков, связь кажется очень слабой.

#todo Умение интерпретировать графики очень важно для дата-сайентиста и сокращает время работы
#todo над разведывательным анализом данных. Опытным специалистам по данным требуется несколько секунд,
#todo чтобы определить характер связи: линейная/нелинейная, прямая/обратная, — а также силу связи,
#todo или коэффициент корреляции. 

#todo При положительной корреляции увеличение одного признака приводит к увеличению другого. И наоборот.
#todo При отрицательной связи увеличение одного из признаков приводит к уменьшению другого и наоборот.
#todo При нулевой корреляции признаки распределяются независимо друг от друга, что видно на рисунке.

#todo При сильной связи точки на графике расположены близко друг к другу. Чем связь слабее,
#todo тем дальше находятся точки друг от друга.

#* Диаграмма рассеивания в данных — удобный инструмент анализа, но, к сожалению, только для пары признаков.
#* Тепловая матрица корреляций удобна для анализа всего датасета, но показывает только силу и направления
#* корреляции (плюс/минус), а информации о распределении признаков мы не получаем. 

#? ГРАФИК ПОПАРНЫХ ОТНОШЕНИЙ PAIRPLOT

#todo Давайте построим график PairPlot для нашего набора данных:

sns.pairplot(data)

#* Структура похожа на изученную нами тепловую матрицу корреляций. На осях х и у расположились
#* признаки из набора данных. На главной диагонали вместо единиц представлены графики-распределения
#* конкретной величины. В остальных ячейках мы можем увидеть точечный график связей признаков между
#* собой — это scatterplot, который мы строили для пары признаков. Здесь это пара признаков,
#* которые пересекаются между собой.

 